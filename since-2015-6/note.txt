VirtualBox
    virtual box安装ubuntu花屏,重新切换图形显示
    sudo apt-get install virtualbox-guest-dkms重启以支持更高分辨率
    virtualbox用nat连接网络需要做端口转发以登陆进去，或使用bridged network，获得
        本地局域网的ip
    GRUB_CMDLINE_LINUX_DEFAULT=" quiet splash"改成“text”就不再启动X，可以手动
        执行startx来启动图形化
    VBoxManage list vms
    VBoxHeadless -s <Guest-OS-Name>
    给XP共享文件夹，通过Win+E的网络邻居里找，拖拽功能仅支持linux
    ubuntu7.04-server中安装openssh-server需要安装光盘，如果再virtual-box中需要开
        启虚拟光盘，但安装后记得卸掉，不然启动时会从光盘启动（应该可以调启动顺序
        ），还得手动选择从磁盘启动
    获得桥接网卡且headless运行host的ip地址
        for i in {1..254}; do ping -c 1 192.168.178.$i & done
        VBoxManage list runningvms
        VBoxManage showvminfo <vmname>
        arp -a | grep <vmname-mac-addr>

    VBoxManage modifyhd ".......vdi" --resize 81920


git:
    git tag -a 创建annotated tags，不加参数为lightweight tag
    git show v1.0.0显示tag详细信息
    git push --tags 或 git push v1.0.0提交tags
    git checkout -b version2 v2.0.0这么做，如果再commit tag会被改变，所以尽量
        避免这样做，可以找到hash，手动checkout
    git reset --soft HEAD~1取消上次的commit
    git push -u origin feature_branch_name将本地branch push到origin
    git push origin --delete <branchName>删除远端branch，tag可以用类似方法删除
    git push origin :<branchName>删除远端branch，tag可以用类似方法删除
    git log --oneline / git log --pretty=oneline --abbrev-commit
    git config --global alias.slog "log --oneline"
    alias.slog=log --oneline
    alias.clog=log --pretty="format:%C(yellow)%h %Cblue%>(11)%ad %Cgreen%<(10)"
        "%aN%Cred%d %Creset%s" --date=short
    git checkout master之后执行git merge feature2，将feature2中新增内容
        merge到master上，如果master没动过就是fastforward
    git remote -v
    git remote set-url origin <url>
    git rebase --interactive <要修改commit message的地方>
    git pull --rebase 避免多余的merge commit
    git pull --prune 删掉remote不存在的本地branch
    git rebase master，rebase到master上，同上，这样做后可能需要force push到origin
    git commit --amend
    git log --graph --oneline --all
    git log --follow -p -- file查看某文件的历史记录
    gitk [filename]
    gitk --all显示所有branch
    git reset --merge <>将当前branch回归到某个点
    git diff、diff都是得到的是new相对于old的变化diff old new
    git rebase -i --root合并前两个commit
    git rebase --onto commit-id^ commit-id去掉某个commit
    git rebase --onto master next topic
    git config --global --unset <config>

    git diff
        参数：path  old-file  old-hex old-mode  new-file  new-hex new-mode
        因此对某些外部diff工具需要一个wrapper
        git config --global diff.external ~/scripts/my_diff.sh
        ~/.gitconfig
    git difftool
        默认使用diff.tool的配置
        每个difftool可以设置 difftool.<toolname>.path和difftool.<toolname>.cmd
            但标准支持的difftool只设置path即可或者放到PATH环境变量里
        difftool默认支持meld和bc3，这两个很好用
        使用时加上-d可一次性比较所有文件，否则是线性比较
    让centos自动补齐git
        for file in /etc/bash_completion.d/* ; do
            source "$file"
        done
    git rev-parse --abbrev-ref HEAD 获得当前branch
    git show a2c25061 显示某hash的内容
    git push --all origin

    删掉branch中有关某些文件的历史
    git filter-branch --commit-filter 'if [ z$1 = z`git rev-parse $3^{tree}` ]; then skip_commit "$@"; else git commit-tree "$@"; fi' "$@"
    git filter-branch --tree-filter 'rm -rf my_folder' --prune-empty -f HEAD
    git filter-branch -f --index-filter 'git rm --cached --ignore-unmatch Rakefile' HEAD
    git filter-branch --index-filter "git rm -r --cached --ignore-unmatch <file/dir>" HEAD
    A previous backup already exists in refs/original/，把.git/refs/original/删掉或者-f

    git merge origin/refactor不要加空格，否则提示"Already update to date"
    git: double dash "--" means "end of command line flags"
    git log --all -- <path-to-file>
    git show <SHA> -- <path-to-file>

    清掉所有修改
    git clean -df
    git checkout -- .

    设置git自动根据系统checkout特定的换行符
    find . -type f -not -path "./.git/*" -exec dos2unix {} \;
    git commit -a -m 'dos2unix conversion'
    echo "* text=auto" > .gitattributes

    将本地branch设置成origin的HEAD
    git reset --hard origin/master

    git config --global core.pager 'less -x1,5' 4个空格显示
    git config --global core.editor emacs

    git apply可用来apply patch，但会根据patch中的label自动匹配需要修改的文件
        diff --label <prev> --label <curr>可以设置label

emacs
    emacs不能正确刷新文本导致显示messy的问题：
    emacs按字搜索：M-s w
    默认emacs会自动添加最后的换行(setq mode-require-final-newline nil)
    emacs更改文件后导致buffer的文本不正确,去掉TERM=xterm-256color,重启shell后又
        好了，但是之后再加上也没事了。该问题应该与xterm有关
        因为文件中有中文注释，去掉后再打开就好了
    query-replace-regex
    replace-regex
    M-. tag RET/M-*/C-u M-./C-x 4 . tag RET
    man-entry直接看manpage
    C-u M-x align-regex可多列对齐
    C-x RET r dos RET 避免显示^M

    C-x r M-w/C-x r y  拷贝粘贴
    C-x r N插入数字

    C-x (开始录制宏，C-x )结束宏，C-u 10 C-x e执行10次

    clipboard-yank

    wrong type argument : arrayp , nil把对应的package从配置目录删除，重新初始化

    重复上一条命令C-x z或C-x ESC ESC

VIM
    window
        split/vsplit(sp/vs) file
        hide/only/close
        ls(buffers)
            u   列表外缓冲区 |unlisted-buffer|。
            %   当前缓冲区。
            #   轮换缓冲区。
            a   激活缓冲区，缓冲区被加载且显示。
            h   隐藏缓冲区，缓冲区被加载但不显示。
            =   只读缓冲区。
            -   不可改缓冲区， 'modifiable' 选项不置位。
            +   已修改缓冲区。

            buffers! 显示列表外缓冲
        缓冲命令
            buffer         编辑一个缓冲区
            bnext          编辑下一个缓冲区
            bprevious      编辑前一个缓冲区
            bfirst         编辑第一个缓冲区
            blast          编辑最后一个缓冲区
            bdelete        删除一个缓冲区
            sbuffer 3
        e(edit) filename
        n [filename]切换到某个文件
        bd 关闭buffer
        ctrl-w 上下左右
        ctrl-w ctrl-w    - move cursor to another window (cycle)
        ctrl-w =  让所有window等大小
        windo/bufdo 所有window/buf做同样操作
    so ~/.vimrc加载配置，与前者同时使用可都加载
    qall（qa)
    mksession ~/mysession.vim
    source ~/mysession.vim
    vim -S ~/mysession.vim
    $/0/^/A/I
    e/b/w按字移动
    v：之后d/y，之后可以p
    Ctrl-v: 之后I/A/r/d/c进行列编辑，按esc确认结果
    zz/zb/zt将当前行作为中间、顶、底
    Ctrl-e/y 滚动一行
    Ctrl-d/u 滚动半页
    Ctrl-f/b 滚动一页
    u1|u rever-buffer到。。。
    H/M/L屏幕内cursor移动
    D删除光标到行尾
    gg/G文件头尾
    dw删除字
    dt'删除直到'，'可以换成任意字符
    [n]<>可以增加减少缩进
    注释多行 Shift I # Esc
    选中文本，然后u/U进行case转换
    使用P（insert粘贴）而不是p（append粘贴）来粘贴
    wa 全部保存
    redo ctrl+r/ undo u
    行尾追加: s/$/,/

    range
        21     line 21                                     :21s/old/new/g
        1      first line                                  :1s/old/new/g
        $      last line                                   :$s/old/new/g
        .      current line                                :.w single.txt
        %      all lines (same as 1,$)                     :%s/old/new/g
        21,25  lines 21 to 25 inclusive                    :21,25s/old/new/g
        21,$   lines 21 to end                             :21,$s/old/new/g
        .,$    current line to end                         :.,$s/old/new/g
        .+1,$  line after current line to end              :.+1,$s/old/new/g
        .,.+5  six lines (current to current+5 inclusive)  :.,.+5s/old/new/g
        .,.5   same (.5 is interpreted as .+5)             :.,.5s/old/new/g


    行移动
        nnoremap <A-j> :m .+1<CR>==
        nnoremap <A-k> :m .-2<CR>==
        inoremap <A-j> <Esc>:m .+1<CR>==gi
        inoremap <A-k> <Esc>:m .-2<CR>==gi
        vnoremap <A-j> :m '>+1<CR>gv=gv
        vnoremap <A-k> :m '<-2<CR>gv=gv

    gd/gD goto local/global declaration
    g*/g# search word under cursor forward/backward
    Ctrl+O/I(TAB) to older/newer cursor position

    lcd/pwd/grep
    可以用V模式，替换一片区域，但是仍然不能选择

    sudo apt-get install exuberant-ctags自带的tags不好用

    行号：set number/nonumber

    tag：
        ctrl + ]  查找当前对象定义
        ctrl + o 回退

    convert case：
        gUiw/guiw 更改当前字
        gUU/guu 当前行
        U/u 在v模式下更改选中部分

    plugins:
        plug manager
            vim-plug
            vundle
        vim-easy-align

sublime：
    "rulers": [80, 120]设置ruler

抓包
    使用tshark -q -r input.pcap -z follow,tcp,ascii,$stream > $stream.txt
        所得为ascii数据，所有非可见字符都使用'.'(0x2E)填充，并非原始数据，因此解压不
        了，使用tcpflow获得的为二进制数据，可以正常解压。使用follow,tcp,hex或者
        follow,tcp,raw获取的数据都是转成hex的，非原始二进制数据，因此都解压不了
    tcpdump
    tcpdump -w xpackets.pcap -i eth0 dst 50.31.164.226 and port 80
        这样只能抓发往50.31.164.226:80的数据，但是response收不到
        要抓response不要指定端口，但这样会把所有的流量都抓住
    tcpdump -tttt -r data.pcap读取已经抓的包
    tcpflow能把.pcap的http包分析出来
    tcpflow/tcpdump都是使用libpcap，expression的格式是一样的：
        expression有一系列primitives组成，通常的primitive包含id和多个前缀qualifiers
        qualifiers包含type/dir/proto，但也有复杂的primitive
        -l Make stdout line buffered
        -A Print each packet (minus its link level header) in ASCII
        -i 指定interface，默认使用‘lowest numbered’
        -n Don't convert host addresses to names
        -X 打印数据in hex and ASCII

获取系统进程状态/参数，与内核通信等
    /proc/pid/statm  /proc/pid/stat  /proc/pid/status查看pid的内存、user、sys时间等
        信息；cpu利用率可通过(user + sys) / clock获得
    /proc/diskstats 2.6的内核可通过该文件获取磁盘利用情况（3以上的内核貌似沿用了2.6的
        设置）
    /prpc/net/dev 网络信息
    读取/proc中的数字目录数获取进程信息
    目前检测内核thread的方法为看comm中是否包含/，该方法并不正确：
        kthreadd (PID 2) has PPID 0 (on Linux 2.6+)
        /proc/*/exe为空
        /proc/*/cmdline空 ，used by ps and top to distinguish kernel threads.
    磁盘信息可用statvfs/statfs获取
    /proc/19873/smaps可获得进程内存占用的PSS指标

    情况linux缓存echo 3 > /proc/sys/vm/drop_caches

    查看进程的线程个数，ps -eo nlwp或者/proc/pid/task或者/proc/pid/status
    已打开的文件列表/proc/<pid>/fd/，进程限制/proc/<pid>/limits

    pctrl可修改进程的/proc/pid/comm|stat中的名称，/proc/pid/cmdline需要修改argv[0]

    grep cgroup /proc/mounts查看cgroup挂载点
    /proc/cgroups列出cgroup子系统
    /proc/<pid>/cgroup查看进程所在cgroup（里面的路径是相对于挂载点的
    每个container都会有一个cgroup，对LXC名称为lxc/<container_name>，老版本是
        <container_name>；对docker为/docker/<longid>/
    cgroup的内存占用需要在内核中开启cgroup_enable=memory swapaccount=1
    内存信息在memory，cpu在cpuacct，时间单位为USER_HZ，为当前已用
    有多少个container通过docker api获取

    /proc/pid/fd中socket中的数为inode，使用该inode可以在/proc/net/[tcp|udp|unix]中寻找该socket的详细信息
        有些可能使用的ipv6

    windows：perfmon工具类似SI

    基本上Windows上所有可监控数据都可通过Performance Counter获取(具体看perfmon)

    GlobalMemoryStatusEx 内存和交换分区（page file）使用
    GetDiskFreeSpaceEx 获得磁盘信息
    磁盘利用通过RegQueryValueEx（HKEY_PERFORMANCE_DATA获取，获得的数据为：
        Performance Data Format
    使用counter-index 200/202/204来获取磁盘利用%也可以（地址是相连的部分，值相
        同），但该值有多个COUNTER（后一个为base-counter，辅助计算），还是
        使用1400/1402/1404来获取
    windows-performance-counter是18-digit Active Directory timestamps, also
        named 'Windows NT time format' and 'Win32 FILETIME or SYSTEMTIME'.
        The timestamp is the number of 100-nanoseconds intervals since Jan 1, 1601 UTC.
    Impersonation and Delegation
    网络数据可通过GetAdaptersInfo和GetIfEntry获得，但MIB_IFROW为32需要处理溢出
        如果要更好的处理可以通过Performance Counter
    使用GetAdaptersInfo获得的name为内部名称，IP_ADAPTER_ADDRESSES可得到friendlyName


windows下编译zlib/curl/sigar库
    ZLIB：windows上incluede zlib.h，默认为__cdecl，使用win32/Makefile.msc编译的也是
        如果使用的是zlibwapi.lib，则需要在include前定义ZLIB_WINAPI切换
        windows上编译zlib，使用win32下的Makefile，在contrib\vstudio目录下有sln工程，但
        编译出来有问题
    CURL：curl默认使用DLL链接，#define CURL_STATICLIB使用静态库，在linux下没有该问题，
        因为linux下不会单独生成一个.lib的文件，.a的符号是与.so的符号是一致的

        使用vs编译curl：winbuild目录下nmake /f Makefile.vc VC=11 mode=static MACHINE=x64
        curlbuild.h为平台相关的内容，该文件并不包含在git代码库中，而在每日的tar.gz中。cmake
            过程中可生成该文件
    SIGAR：sigar在windows上sigar_proc_exe_get引用sigar_proc_exe_wmi_get，而该函数是在
        一个cpp文件内定义的，需要改成c++编译器Properties>C/C++>Advanced>C++ Code(/TP)
        错误为：Native Compiler support only available in C++ compiler


Wix
    RemoveFolder不指定Directory默认为起父目录，如果有多个父目录报not listed in
        the RemoveFile table.
    Wix里的NOT Installed指的是当前程序还未安装过
    没有权限启动service设置Account="LocalSystem"，当程序不能运行也会报这个错误，
        如缺少DLL等
    本地化通过 -cultures:zh-CN设置，本地化文件.wxl通过-loc设置
    “另一个版本已经安装，先卸载”问题，是Product设置了GUID的问题，设置成*
    AllowSameVersionUpgrades设置成yes，这样同版本安装才不会成为两个，而是当作升级
    candle中定义变量-dMyVariable="Hello World"
    由于WindowsInstall非事件驱动，根据输入enable下一步并不会自动刷新，需要切换
        dialog才能刷新，但licenseAgreement界面的checkbox可以
    调试DLL的CustomAction可以在DLL前搞个MessageBox，然后附加调试，或者使用MsiBreak
    DLL默认导出的符号有Decoration，在wix中使用时需要保持符号名称在DLL中存在，因
        此最好使用上面的方法将其Decoration去掉
    KeyPath用于表示一个component，WindowsInstall使用其对应资源确定该Component是
        否损坏和需要修复，因此最好的做法是一个文件一个component这样当文件丢失时，
        WI可以修复，如果多个文件，但KeyPath文件存在WI会认为其没有损坏
    如果添加到Programs的folder内容为空，Wix不会生成该目录，至少要一个item才行，
        可以使用CreateFolder创建空目录，但不能创建空文件
    AO_WixUI_FeatureTree的Back最高的order为2，要想覆盖该设置需要设置更高的order
    customaction设置了sequence后仍是随机执行的，不保证顺序
    Wix使用IniFile可直接更改Ini文件，可在安装过程中修改，可避免用customAction输
        出到ini文件带来的权限及顺序问题，Ini修改应该是在安装Component过程中进行
        的，且在StartService之前。类似的，Wix也支持对xml格式的配置进行设置
    CustomAction如果需要权限应设置Execute="deferred"或者Commit且Impersonate="no"
    Advertised只有个feature可用，但是并没安装，当用户想使用时（点击快捷方式）再
        安装，而non-advertised则是直接安装上
    WindowsInstall定义了一些Property（变量，比如CommonAppDataFolder等），wix本
        身也有些Built-in Variables，两者有重复
    Wix中的变量必须要加var.前缀才能访问


    candle的-arch会设置sys.BUILDARCH和sys.PLATFORM，默认为x86，如果该设置与
        ProgramFiles目录设置不匹配会报error，因此ProgramFiles需要根据arch设置，
        如果安装包里既有32又有64，可用component的Win64属性设置
    Package的Platform属性也可以设置arch，但推荐使用-arch




Docker
    加tag，类似rename：docker tag d583c3ac45fd myname/server:latest
    如果从scratch创建docker image需要该程序静态链接或者自行安装依赖
    sudo docker build -t myrepo:getcpu .  前面是repository后者为tag，需要
        当前目录下有Dockerfile
    docker rm 删除container，-f
    docker rmi
    docker run
    docker ps -a查看所有container
    docker run -d -p 80:80 nginx-1.9.1:latest
    sudo docker -H tcp://127.0.0.1:2375 -d &让docker监听非默认端口
        这样执行任何命令都需要指定-H，否则会报连接不到docker
    Registry 存放一系列镜像
    repository 存放某一类镜像的各个tag
    docker command的执行由用户提交传递给docker daemon，而-H指定的就是这个命令
        提交地址使用docker search [ip/host]/term搜索时，实际链接的-H的地址，然后
        转给daemon
    cpu/memory分别在cpuacct.stat/memory.stat，dockerAPI也可用top获取


Docker Remote API
    unix:///var/run/docker.sock
    GET /containers/json?all=1&filters={"status":["running"]}&limit=100 HTTP/1.1
    GET /containers/<id>/top?ps_args=-eopmem,pid,comm HTTP/1.1(必须有pid)
    GET /containers/<id>/json
    GET /images/json
    GET /images/search?term=XXX
    GET /info

Docker
    添加registry
        修改docker.service
        ExecStart=添加 --registry-mirror=https://docker.mirrors.ustc.edu.cn
        systemctl daemon-reload
        systemctl restart docker
    保持container运行
        docker run -d centos tail -f /dev/null
        docker run -t -d centos
        docker run -td -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root docker.io/mysql:latest
    docker ps -f "status=exited"
    docker ps -f "status=exited" | awk 'NR>1{print $1}' | xargs docker rm -f

squid3使用
    带用户名密码的proxy需要支持Proxy-Authorization的proxy server
    apt-get install squid
    service squid3 restart
    apt-get install apache2-utils
    touch /etc/squid3/squid_passwd
    chown proxy /etc/squid3/squid_passwd
    htpasswd /etc/squid3/squid_passwd test
    auth_param basic program /usr/lib/squid3/basic_ncsa_auth /etc/squid3/squid_passwd
    acl basic_ncsa_users proxy_auth REQUIRED
    http_access allow basic_ncsa_users
    squid默认监听3128，配置为http_port 3128


WSGI uWSGI WebDAV
    WSGI，web-server与python应用之间的接口
    uWSGI
    以下均为协议：
        uwsgi（uWSGI server实现的用于传输数据的binary协议，可以用来传输HTTP请求
        scgi（sinple cgi）
        fastcgi
    WebDAV：Web distributed Authoring and Versioning，类似ftp
        类似ftp，但相比ftp，WebDAV有HTTP的一切好处（基于HTTP），如加密、认证、压缩、
            保持连接，传大量小文件较快
        SFTP也有如加密、认证等等功能


curl
    curl --unix-socket 7.40以后支持
    curl: (48) An unknown option was passed in to libcurl，curl正确，但libcurl版本
        不正确，使用ldd看看是否使用了正确的libcurl库
    curl默认使用strlen计算content-length，如果想发送binary，需要使用CURLOPT_POSTFIELDSIZE
    curl的proxy username/password仅需要对':'做encode。

    编译带ssl的curl./configure LIBS=-ldl --prefix=/root/code/curl64 --with-ssl=/root/code/openssl64/
        --disable-ldap --without-libidn --enable-shared=no
        disable-ldap后configure报找不到ssl，其实是没有加-ldl，一定要使用disable-ldap
        使用without-ldap，在curl发现有系统库后仍会使用ldap

    ignore_expect_100 on不然带expect的报The requested URL could not be retrieved
    这个不管用server_http11 on
    这个问题应是由于curl默认使用HTTP/1.1导致的，下版改成HTTP/1.0

    CURLOPT_SSL_VERIFYPEER 是否verify perr的certificate


Windows配置及工具使用
    appwiz.cpl打开卸载程序
    控制面板对应的命令为control

    tasklist /m blueware.profile.dll查看是否有进程加载该dll
    dumpbin /all 在.text段可看到IL code使用RVA查看方法体
    dumpbin /headers查看64或者86
    nmake里的macro类似make里的variable，引用方法也相同，大小写敏感，需要注意的是nmake
        本身的关键词是大小写不敏感的
    vs中ERR, hr可查看上一个错误
    gacutil -i <> 安装某个.net的DLL，有时.net的msi安装包安装不上，有时报找不到
        某个库的某个符号，但该版本的DLL都是正确的，原因有可能为该DLL未注册上
    解压msi包：msiexec /a /path/to/msi /qb TARGETDIR=/absolute/extract/path

    windows xp系统名称里，只要没写64那就是32
    vc++2012编译的程序在xp上报：Invalid win32 application.安装vs2012 update1/3/4
        安装update2貌似不行，然后在项目属性General -> Platform toolset里选择v110_xp
    Tools – Options – Projects and Solutions – 取消打开错误列表选项.
    vs2012 solution explorer有个预览，关闭就可以取消在右边打开文件

    windows本地策略->审核策略->开启登陆审核，这样才会记录错误登陆事件
    键盘按键慢，可设置键盘的字符重复速度

    Project Settings -> Configuration Properties -> C/C++ -> Advanced -> Show Includes
        查看include-tree
    sc create MathsService binPath= %SYSTEMROOT%\System32\Maths.exe type= own type=
        interact start= demand DisplayName= "My fabulous Maths service"
        安装service
    msiexec安装程序，/i /x /l*(输出日志)，可查看帮助看看
    net start/stop和sc start/stop都可用来管理服务，但sc直接返回不会等待启动完成

    在notepad++中查找unicode字符[^\x00-\x7F]，vs的warning C4819


bat脚本
    变量赋值set xxx=yyy等号前面的空格会被当成变量名，后面的空格会被当作值
        因此需要注意，引用改变量使用%xxx%
    if不支持 and or，需要自行实现
    goto标签的冒号在前面
    查看帮助，直接在cmd里输入if /?
    echo.才能输出空行，否则只是显示是否处于打开状态
    %~dp0，可以参考for /?

    "echo."可以打印字符串，"."后面的都会被打印出来
    当前路径为%~dp0
    cmd里的函数用goto标签实现，函数结束为goto:eof，然后call标签就行
    exit默认会连上层cmd一块退出，使用exit /B
    cmd里的注释使用"::"，设置变量使用set xxx=yyy，然后通过%xxx%引用

    避免某个bat影响当前环境，使用setlocal/endlocal
    setlocal
    call %VS100COMNTOOLS%vsvars32.bat
    devenv myProject.sln /Build "Debug|Win32"
    endlocal

    将命令的输出作为变量值：
    for按行处理，但以下语句得到的是第一个token
    for /f "delims=v-" %%i in ('git describe --tag --long') do set OA_VERSION=%%i

windows编程
    strcasecmp最初出现在string.h，glibc中有，但posix标准将其定义在strings.h中
    snprintf保证最后一个字符为0，windows下的_snprintf不保证这点
    windows上的select中至少有一个fd-set必须不为null，且还得有至少一个handle，因
        此用来不好用来实现nanosleep
    __impl__是windows的动态库链接用lib的符号前缀
    DLL导出的符号必须要__declspec(dllexport)、#progma(linker)或者使用DEF表
    __stdcall即WINAPI，由callee释放栈，不适合变长参数函数，这类使用__cdecl
    Windows下DLL会在PATH目录中搜索，优先级稍微靠后

    忽略编译警告：c/c++高级，忽略特定警告（只有数字，不包含前面的c）
    忽略链接警告，在所有选项的命令行里：/ignore:4099，但是4099被标定为不可忽略。。
    4244;4018;4267
    nmake里INCLUDE 和LIB都是预设好的指向vs目录的，覆盖后会提示找不到头文件等错误

    在命令行里使用v110_xp除了要使用vcvarsall还要设置INCLUDE/PATH/LIB/CL/LINK等变量，
        并在编译时添加/D_USING_V110_SDK71_(设置了CL貌似就不用了)
    cmd在if里设置环境变量如果存在带空格路径会报错，在if外就没事

linux编程
    有些符号如果是用宏生成的，搜索时需要注意
    memset std::string导致崩溃。。。。
    linux下堆上申请的空间在未使用时是不占用内存页的，实际写入时再分配，因此仅malloc在
        free中是看不到的
    glibc是向后兼容的
    makefile里的target，如果没有prerequisites，且当前目录下已经有同名文件/目录，make会
        把其当作up to date，而不去执行，这时将其放入.PHONY中即可避免该问题

    SIGCHILD被mask不会影响wait/waitpid

    setlocal非常损耗性能，不嗯作为循环内函数
    snprintf/vsnprintf对性能影响较大，基于循环的拷贝次之，memcpy就好些（估计被优化过）

    全局变量可以声明一次，然后在后面再初始化，初始化必须加上类型表示，比如：
        int global;
        int global = 1;

    C里面（）表示函数接收任意个参数，（void）表示接收0个参数
        使用strict-prototype后，如果定义了（）但没使用其参数，会报warning

    strspn/strcspn

    Cproto获取C文件中的函数列表

    centos5.5下编译找不到pthread_mutexattr_settype，需要定义-D_GNU_SOURCE

    对于对齐的变量的读写操作硬件保证不会出现一半旧一半新的情况

    dyncall库可以动态调用C中的函数
    表示section开始结尾：__start_SECTION and __stop_SECTION，如果段为空，则对于符号未定义

    对外使用的数据结构要定义在.h中，否则编译会有incomplete type错误

    shmget设置的shared memory不会自动在引用进程数为0时自动删掉，看一下mmap
gdb
    shell command
    follow-fork-mode
    detach-on-fork
        为on，根据follow-fork-mode其中一个被debug，一个detach
            需要注意的是，只有第一个child会被catch，所以如果遇到某个断点怎么都触发不了
            可能是因为该断点不在第一个child触发导致
        为off，根据follow-fork-mode一个debug一个suspended

    info inferiors/locals/args
    inferior <N>
    handle signal <op>
    info signals [signal]

    terminal的输出变乱（按回车会打印PS1但并不换行，输入也不显示），是echo被关闭导致
        可使用reset，或stty echo打开echo（stty -echo用来关闭echo）
    gdb启动出现《PRESS ENTER时，就会出现关闭echo的问题，启动gdb时扩大terminal大小就没问题
        该问题也会导致上面的问题
    看内存：x/nfu addr, nfu means: repeat count, format, unit size
        format: ‘x’, ‘d’, ‘u’, ‘o’, ‘t’, ‘a’, ‘c’, ‘f’, ‘s’
        unit size:
            b Bytes.
            h Halfwords (two bytes).
            w Words (four bytes). This is the initial default.
            g Giant words (eight bytes).
    set detach-on-fork off可以同时调试parent-child

    printf "%s\n", string

    打印数组：p *list@20

    内存断点 watch/rwatch/weatch

    条件断点break x:20 if strcmp(y, "hello") == 0


gcc/gcov
    -fdata-sections -ffunction-sections -Wl,--gc-sections去掉不用的函数，这样就是其他函数是
        外部符号也能够生成elf
        这需要在编译源文件时指定-fdata-sections -ffunction-sections，已生成的.o不起作用
    获得默认include路径
    gcc -xc -E -v -
    gcc -xc++ -E -v -
    gcc -Wp,-v -x c++ - -fsyntax-only
    gcc -print-prog-name=cc1plus` -v显示include路径

    g++ 4.6 issue no <bits/c++config.h因为没有安装g++的开发库libg++.devel

    ar rcs libout.a out.o生成静态库

    I was using _exit() to terminate the child process, and it has the property of
    bypassing any finalization on the process, and with it the call to __gcov_flush()
    -- this is why I wasn't getting any coverage.

    安装pip：get-pip.py
        python get-pip.py
    code coverage可以使用gcov，用gcovr或lcov生成结果
        编译-fprofile-arcs -ftest-coverage链接阶段-lgcov，--coverage可替代前两者
        exit可以gcov得到，_exit，_Exit会导致__gcov_flush不被调用而得不到coverage

        gcovr -r .. -e 'test.*' -e 'third*' --html --html-details -o daemon_cov.html

    -H -M显示include tree，-MM跳过系统头文件

    GCOV_PREFIX/GCOV_PREFIX_STRIP 设置gcda输出位置，但是使用gcov时仍然需要拷贝回object目录
        否则gcov不能正确寻找对应文件

    .gcno编译时生成，记录行号及块信息
    .gcda运行时生成，记录实际执行的位置及分支，多次运行会追加

    gcov-tool可以用来merge.gcda文件，2014.9后的版本才有，还得从源码编译

    创建shared library时，gcc默认所有全局符号都会被导出（visibility=default）
        可以设置-fvisibility=hidden，再对需要的符号设置visible
    gcc -rdynamic 将所有符号放到dynamic symbol table, dlsym/backtrace都需要
        非动态符号（导出符号），使用dlsym是得不到其地址的

    通过环境变量设置include路径：C_INCLUDE_PATH CPLUS_INCLUDE_PATH或者CPATH
    library路径：LIBRARY_PATH

ld
    /lib/ld.so a.out dynamic linker/loader
    /lib/ld-linux.so.{1,2} ELF dynamic linker/loader
    /etc/ld.so.cache
        File containing a compiled list of directories in which to
        search for shared objects and an ordered list of candidate
        shared objects
    /etc/ld.so.preload
        File containing a whitespace-separated list of ELF shared
        objects to be loaded before the program.
    RPATH里可以使用：$ORIGIN可以用相对路径，$LIB解析成lib/lib64,$PLATFORM

    加载某个动态库除了LD_PRELOAD，还可用/etc/ld.so.preload，但后者是全局的
        或者使用ptrace ATTACH到进程，向暂时无用的代码段写入代码，修改寄存器来执行

    RPATH中的$ORIGIN被解析成ELF所在路径，可以使用chrpath修改RPATH

    -init,<function name> -fini可用来指定.so的ctor/dtor,这会在.so中生成对应section
    __attribute__((constructor))好像是等效的。
    貌似用-init和-fini不如使用名为init/fini的函数名称，其他的可以

杂项
    DistroWatch可查看个linux/bsd发行版携带的软件版本情况，及其他各类信息
    Ini文件里如果不指定Section，那就是Global，但仅对第一个section前的部分
    %22 %5B %5D %2F，对应"[]/。为其hex值

压缩相关：
    使用deflateInit压缩的，需要使用inflateInit，或者使用inflateInit2，wbit为15或者
        MAX_WBITS+17,文档上写15可以，但32(MAX_WBITS+17)为什么也可以？另外
        MAX_WBITS+32可自动判断zlib/gzip，+16只能是gzip

    zlib/gzip/zip通常都是使用DEFLATE压缩数据格式，但wrapper（header和trailer）不同，
        <None>/.gz/.zip是上面数据格式对应的文件后缀，其中zlib wrapper一般在png文件中使用
        .gz仅针对单个文件，因此常与.tar一起使用；.zip是归档。
    zlib是一个库，支持三种在DEFLATE格式上的Wrapping：raw deflate(no wrapping)，
        zlib wrapping(png格式使用)，gzip wrapping。zlib/gzip warpping的区别在于前者
        更紧凑，adler-32校验速度快于后者使用crc32校验
        window bits: -15 ~ -8 raw deflate
                       8 ~ 15 zlib wrapping
                      24 ~ 31 gzip wrapping (header和trailing基本为空)
                                            (可以使用gunzip工具解压)
    gzip/zip：前者为zlib的gzip wrapping一样，只是gzip wrapping的header中name等字段为
        空；zip等同于tar后执行compress，但一般的压缩算法为deflate
    zlib wrapping：header一般只有两个字节，标明method和windowbits；trailing为4字节
        adler-32校验和
    minizip库可处理zip

iptables
    iptables/netfilter is the userspace/kernel module

    tables->table->chains->rule->target(action)
    rule从上到下匹配，第一个匹配后停止，无匹配使用默认

    lsmod | grep ip_tables
    rpm -q iptables

    iptables -nL --line-numbers

    iptables -D chain rulenum删除chain中的rule或某个reference
    iptables -X chain 仅当无reference
    iptables -F [chain] 删除所有rule，不加chain则flush所有chain

    iptables -N LOGGING
    iptables -A INPUT -j LOGGING
    iptables -A OUTPUT -j LOGGING
    iptables -A LOGGING -j LOG -m limit --limit 2/min --log-prefix "Dropped: " --log-level 4

    允许访问mysql，使用insert放在reject前
    iptables -I RH-Firewall-1-INPUT 9 -p tcp -m tcp --dport 3306 -j ACCEPT

    配置iptables和selinux：system-config-securitylevel
    保持iptables：service iptables save

    /etc/syslog.conf  kern.warning   /var/log/custom.log
    /etc/sysconfig/iptables

linux命令使用
    sudo apt-get install openssh-server支持ssh登陆
    让ssh保持连接，在/etc/ssh/sshd_config中添加
        ClientAliveInterval 30
        ClientAliveCountMax 5
    ssh-keygen -t rsa -b 4096 -C "your_email@example.com"
    ssh-keygen -y -f ~/.ssh/id_rsa > ~/.ssh/id_rsa.pub, 从私钥获得公钥
    ssh可信登陆需要在目标主机中添加本主机的公钥，一般在~/.ssh/authorized_keys
    互信登陆只需要编写~/.ssh/authorized_keys就可以

    ubuntu开启root的ssh登陆
        sudo passwd root
        sudo passwd -u root
        /etc/ssh/sshd_config中的PermitRootLogin设为yes
        service ssh restart

    nice命令可修正程序優先級（仅是指导性的），默认为10
        优先级范围为[-20~19]，越小越高
        程序的nice为指导性修正值，一般都是0
    ntpdate使用NTP协议获取时间
    free中的-+部分，对应实际占用
    jobs/disown/fg/bg/跟作业管理相关，disown解除关系（不再在shell接受到HUP时向该进程发
        送HUP）,使用时jobspec需要加前缀%
        先将作业stop（Ctrl-z）然后bg即可将作业放置后台
    查看sector size：sudo hdparm -I /dev/sda | grep -i physical
        sudo fdisk -l

    重启网络ifdown/ifup，/etc/init.d/networking restart是重启所有网络
    ip link set eth0 promisc on
    ip link set eth0 multicast off
    strace防止参数被truncate，-s strsize。-o outfile

    id获取用户id（root为0）
    $$当前进程pid
    ${varname:=value}值未设置或为空时设为value
    ${varname=value}值未设置时设为value
    上面两个命令前面加：避免bash把结果当命令执行
    bash里的变量一旦设置就是全局的，只有加前缀local的为临时变量
    tmp=${var-text}当var未设置或为空使用text
    bash中子进程不能修改父进程中的变量，是两份变量，比如管道
    ps按命令查找pid，ps -o pid= -C php-fpm
    ps过滤进程，-p 2，-u root，跟-e冲突
    sh里没有trap ERR，bash里有，可以用来在某条命令出错时执行
    Makefile里执行shell：$(shell <command>)
    >/dev/null 2>&1 顺序反了不行. 或者使用 &>/dev/null
    declare -a Array=($server)使用IFS分割生成数组，访问方法：${Array[0]}
    cut -c -10,14-
    grep -w可以按word搜索
    grep -r $'\r' *  $'' for c-style escape in Bash
    grep -axv '.*' file搜索非utf8字符  -x 进匹配，-v反转
    awk -F'\t' '{sum+=$3} END { print "Average = ",sum/NR}' < file.log
    awk '{if(min==""){min=max=$1}; if($1>max) {max=$1}; if($1< min) {min=$1}; total+=$1; count+=1} END {print total/count, min, max}' FILE.DAT

    find命令可以使用and or !连接各个过滤选项

    文件的s表示secure deletion，文件删除时会将对应磁盘块清零
    netstat -rn可查看gateway
    netstat -i查看网络状态，P表示Promiscuous


    LVM: logical volume management
        VG: volume group     vg*  vgdisplay/vgextend等命令
        PV: physical volumn  pv*  pvdisplay/pvextend等命令
        LV: logical volumn   lv*  lvdisplay/lvextend等命令
        LV上扩展fs   resize2fs
        空间分配时首先需要将物理分区添加到PV，然后将PV加到VG中，然后LV从VG中申请空
            间，之后在LV上创建文件系统，但PV一旦放到VG中，再更改大小是不会显现的，
            可以添加新的PV
        PV必须时Linux LVM类型的文件系统，为主分区，使用fdisk设置t为8e
        这种方式只能在已经使用LVM的文件系统上，如果一开始不是，只能新创建一个文件系统，然后
            mount到对应位置，当然如果磁盘上当前分区后面有连续空间，应该是能直接扩展的
    df -T 查看文件系统类型
    fdisk -l查看所有物理分区

    centos下设置static ip
        ip,mask,类型：/etc/sysconfig/network-scripts/ifcfg-eth0
        gateway：/etc/sysconfig/network
        DNS: /etc/resolv.conf
        修改后执行/etc/init.d/network restart

    unlink可以删除已打开的文件，若有其他进程打开了该文件，该文件将继续存在并占用磁盘空间
        直到关闭，但此时其他进程可以创建一个同名文件，这两个文件有不同的inode

    需要xshell设置为ANSI色彩
    设置256色 export TERM='xterm-color'
    查看色彩数：tput colors

    make SHELL='sh -x'
    make VERBOSE=1

    valgrind如果进程再目录没权限就无法创建结果log，如php-fpm/nginx/httpd都会使用单独账户运行
    对带有循环调用的函数，不易做profiling

    hostname不一定带domainname，使用hostname -A/-f可查看完整hostname，httpd使用该hostname作为配置
        -s查看缩短的

    systemtap、dtrace，strace，ptrace为内核trace相关，也可以处理上层应用
    valgrind为动态程序分析，需要将程序运行于valgrind的VM中，相比于静态程序分析而言

    httpd无法访问/tmp目录下的文件，提示找不到，但是文件是存在的
        原因：由于安全问题，systemd可以为httpd配置PrivateTmp，即在/var/tmp下生成独立的/tmp文件夹
        将/usr/lib/systemd/system中有关httpd的PrivateTmp设为false，然后systemctl daemon-reload
        即可关闭该选项

    getenforce/setenforce控制SELinux，centos默认开启，ubuntu默认关闭
    fuser file_name  查看谁在使用某个文件
    enca filename查看文件编码
    enconv -L zh_CN -x UTF-8 filename转换编码
    iconv -f encoding -t encoding inputfile
    convmv -f UTF-8 -t GBK -notest filename 文件名编码转换
    ipcs/ipcrm查看和控制 XSI message queue, semaphore set, or shared memory segment identifier

    date +'%:z %Z'  或者  date -R获得时区
    /etc/localtime  centos下使用该文件控制时区，需要从/usr/share/zoneinfo/拷贝或ln过来以更改时区
    /etc/sysconfig/clock
    /etc/timezone
    /usr/share/zoneinfo/
    更新时间 ntpdate time.windows.com
    查看主机时间是否存在误差timedatectl status（老的系统版本不自带）

    在ubuntu15.04中使用text模式
    /etc/default/grub  GRUB_CMDLINE_LINUX_DEFAULT="text"
    sudo update-grub
    对使用systemd（Ubuntu 15.04）的系统还要禁用graphical login manager:
        sudo systemctl enable multi-user.target --force
        sudo systemctl set-default multi-user.target

    自启动服务
        SystemV：update-rc.d(ubuntu)/chkconfig(centos)
            在/etc/rc.d目录创建/etc/init.d的链接
            [KS][number]xxxxxx  K kill, S start, number为优先级
        Upstart：使用initctl
            /etc/init/service.conf和/etc/init.service.override
        systemd：使用systemctl
            /etc/systemd/system/multi-user.target.wants/service.service
            然后enable一下：systemctl enable service.service
        ubuntu从6.10启用upstart，15.04启用systemd
        service脚本可用来控制SystemV（有些版本也支持upstart服务，但是--status-all只显示SystemV的）

    /etc/sudoers包含了sudo的相关信息

    ssh
        -f可以让ssh在执行命令前进入后台，但这样本地会多出一个ssh进程
        ssh  root@10.128.6.234 'sleep 300&'会导致本地stuck，因为stdout还
            与远端的ssh保持连接中，使用nohup同样会保持stdout因此也不行
        ssh  root@10.128.6.234 'sleep 300 2>/dev/null &'本地也会stuck
        ssh  root@10.128.6.234 'sleep 300 >/dev/null &'可断开

        PS：远程运行locust（python脚本）时必须同时重定向stderr，否则程序起不来，原因未知

PHP相关
    编译php报undefined错误，可能是上次make导致，make clean可解决
    php-fpm -t查看php-fpm.conf位置
    php -i | grep ini
    php-fpm.conf中pm*对应管理多少个worker
    php-fpm -R运行root运行

    apt-get install libssl-dev
    yii2需要mcrypt支持
        安装libmcrypt, libmcrypt-devel
        在php源码目录编译mcrypt：phpize;aclocal;./configure;make
        在php.ini中添加extension=mcrypt.so
    yii2 migrate需要使用pdo_mysql，否者报could not find driver
        php编译时的--with-mysql编译的是mysql，两者是不同的
        如果还不行可试试将localhost换成127.0.0.1
    Primary script unknown可能是找不到php脚本，看看nginx中SCRIPT_FILENAME是否配置正确

    抽取php-ext的编译依赖，需要修改phpize/php-config中的prefix获取方法（dirname）
    php-ext debug编译时不带"-g"（可能时设置CFLAGS覆盖掉了）

    编译php5.5.34，make install时出现以下问题：
        cp: cannot stat `sapi/cli/php.1′: No such file or directory
        原因为configure生成的php.1在之后的make clean中被删除掉了
        因为要在同目录下编译zts和nzts，应在configure前进行make clean
        install-pear-installer] Error 255原因为上次下载pear包中途中断，导致失败
            删掉重新下载即可

    #define APM_G(v) TSRMG(apm_globals_id, zend_apm_globals *, v)展开后的结果
        ((zend_apm_globals *) (*tsrm_ls)[apm_globals_id-1])->v
    非zts下的TSRMLS_C为空（不需要TSRM），编译时就会出错，所以使用TSRMLS_CC为比较好的选择
    TSRM thread-safe-resource-mamagenent; ls local storage
    PHP_ php_开头的宏都被设置为对应ZEND_ zend_开头的宏
    TSRMLS_*系列的宏方便同时支持zts和非zts
    zend_execute_data->function_state.arguments返回的值为参数个数，参数在前面存储
    add_next_index_string往数组里append
    add_assoc_zval*类接口调用zend_symtable_update，该函数会检查key是否为数字index
    ZEND_DECLARE_MODULE_GLOBALS声明global变量
        zts  下为： ts_rsrc_id module_name##_globals_id;
        非zts下为： zend_##module_name##_globals module_name##_globals;
    ZEND_GET_MODULE展开后为：
        ZEND_DLEXPORT zend_module_entry *get_module(void) { return &name##_module_entry; }
    ZEND_INI_BEGIN()        static const zend_ini_entry ini_entries[] = {
    REGISTER_INI_ENTRIES() zend_register_ini_entries(ini_entries, module_number
        module_number为startup函数的参数
    sapi_module、SG(sapi_headers)
    AG alloc global
    PHP/zend下的全局变量包括SAPI Globals (SG)、Executor Globals (EG)、Internal Extension Globals APM_G
        php_core_globals PG、output globals OG
    BG为扩展basic_functions的全局
    显示某个模块的PHP_MINFO_FUNCTION中的内容：php -$'\x0e' <extension-name>
        这个好像是内容使用的，其参数为不可打印字符14
    SG(request_info).request_method

    EX execute data

    CG(function_table) compile global

    mysqli_query会将数据获取过来，real_query只是查询

    multi_query执行后需要next_result才能继续执行multi_query

Mysql
    set old_passwords = 0; 使用MySQL 4.1后的加密方法，否则为之前的
        为临时设置，需要在my.conf中设置才可全session生效
    show variables like 'old%';
    mysql5.0默认old_passwords = 1，高版本的client连接时会报ERROR 2049 (HY000):
        Connection using old (pre-4.1.1)，在client中加--skip-secure-auth可使用old
        password，但最好的方法是修改密码，让其使用新的加密方式
        set old_passwords = 0;
        update user set password = password('testpass') where user = 'testuser';
        select user,password from user;可看到密码长度变了
        flush privileges;
    mysqldump -u$user -p$pass -S $socket --all-databases > db_backup.sql
    mysql -u username -ppassword databasename < filename.sql
    show tables from database;
    show databases;

    mysql --help可查看my.cnf的位置即读取顺序
        /etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf

    GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '111111' WITH GRANT OPTION;
    flush privileges;
    如果mysql当前绑定到127.0.0.1，还需要修改mysql配置bind-address：
        /etc/mysql/my.cnf或/etc/mysql/mysql.conf.d/mysqld.cnf
        设置成0.0.0.0可以监听所有网卡
    忘记mysql密码可按下面的方式：
        停掉mysql
        mysqld_safe --user=mysql --skip-grant-tables --skip-networking &
        免密登陆，修改密码：update user set Password=PASSWORD('root') where User='root';

    mysqldump -u <db_username> -h <db_host> -p db_name table_name > table_name.sql
    mysql -u username -p db_name < /path/to/table_name.sql

    快速插入大量数据insert into user select * from user;

python
    UnboundLocalError: local variable 'x' referenced before assignment,这种情况标记
        该变量为global
    python有build-in函数open（类似fopen），os模块也有一个open（类似系统调用open）
    nonblocking的socket在windows上返回10035，而不是EAGAIN
    调用外部命令subprocess.check_call

NodeJS
    npm config ls -l
    npm install如果安装出现，就需要先安装下面的依赖。不能自动安装依赖？？
    npm默认安装在当前目前，使用-g。-g好像也不管用，到/usr/lib下单独安装倒是可以
    sleep@3.0.0 node_modules/sleep
    └── nan@2.1.0

    node的默认模块搜索路径貌似不包含以下路径
    export NODE_PATH=/usr/lib/node_modules:$NODE_PATH

    nodejs中的process.title可以将上面两者都修改掉

Apache httpd
    configure httpd提示找不到libxml2，--with-libxml2=/usr/后成功

    httpd -l显示内置module，MPM也是内置module之一
    apachectl -k graceful  或者  /etc/init.d/httpd reload

    Multi-Processing Module (MPM)
        worker
            a hybrid multi-threaded multi-process web server
            ThreadsPerChild/MinSpareThreads/MaxSpareThreads
        event
            A variant of the worker MPM with the goal of consuming threads only for
                connections with active processing
            --with-mpm=event来启用
            优化Keep-alive的情况
            这个有点类似多线程式的Nginx
        prefork
            non-threaded, pre-forking web server
            MinSpareServers/MaxSpareServers
        mpmt_os2、mpm_winnt

        ServerLimit/ThreadLimit： MaxRequestWorkers的可配上限，需要完全stop才可更改
        StartServers: 启动的进程数
        MaxRequestWorkers: 同时处理的request数上限，不同MPM表达的含义略不同
            apache 2.4可用，2.2中为MaxClients
        MaxClients：同上
        MaxConnectionsPerChild：每个process可处理的连接数上限，超过后退出

        AP_MPMQ_MAX_DAEMONS：最多能启动的daemons个数，prefork下等于MaxRequestWorkers

    AP_DECLARE_HOOK
    APR_DECLARE_EXTERNAL_HOOK
    APR_IMPLEMENT_OPTIONAL_HOOK_RUN_ALL
    ap_hook_handler函数也是通过上面的的宏定义的
        AP_IMPLEMENT_HOOK_RUN_FIRST
    apr_table_setn(r->headers_out,
    ap_set_content_type
    ap_get_loadavg

    hook的执行应该是循环跑的，需要hook自己去检查r->handler是否为自己

    ap_run_mpm
    AP_IMPLEMENT_HOOK_RUN_FIRST(int, mpm,

    restart一次，generation就会递增。Apache里的restart应该等同于reload
    这两个generation有什么区别, 后者初值为0
    Parent Server Config. Generation: 2
    Parent Server MPM Generation: 1

    下面的三个各自含义
    this conn < this child < this slot

    The per-server config is kept on the server_rec, of which there is one for each virtual host,
    created at server startup. The per-directory config is kept on the request_rec and may be
    computed using the merge function for every request.

    设置request内的variable，类似于nginx中的ctx
    my_request_vars* vars = apr_palloc(r->pool, sizeof(my_request_vars)) ;
    /* store stuff in vars */
    ap_set_module_config(r->request_config, &my_module, vars) ;

    and retrieve what we set later in the request:
    my_request_vars* vars = ap_get_module_config(r->request_config, &my_module) ;
    The conn_rec has an analagous conn_config field. Apache provides other contexts that may be
    useful for some applications: each filter and namespace has a context field for its own data.
    These topics will be the subjects of separate articles.

    the request pool, with the lifetime of an HTTP request.
    the process pool, with the lifetime of an server process.
    the connection pool, with the lifetime of a TCP connection.
    the configuration pool

    Name-based vs. IP-based Virtual Hosts

    Apache httpd webserver communicate to Tomcat sever through AJP protocol.

    该hook可以在存在proxy时对request进行修改，ap_hook_handler不行
        ap_hook_fixups Last chance to look at the request before content generation.

    ap_hooks.h ：一般的创建hook的方式
        声明：AP_DECLARE_HOOK等，定义ap_hook_*和ap_run_*和ap_hook_get_*等函数
        实现：AP_IMPLEMENT_HOOK_VOID等，实现上面的三个函数
    apr_optional_hooks.h mod_status使用的该hook方式
        这种方法不存在ap_hook_*式的hooking方法，需要使用APR_OPTIONAL_HOOK
    mod_info里包含了内置的所有hook

    apache里的filter需要先ap_register_output_filter，然后在insert_filter里
        ap_add_output_filter，这种方式filter会被执行多次，需要在filter函数里
        把自己去掉ap_remove_output_filter
        为什么会执行多次？
        每次都需要在insert_filter里添加才能执行？add跟request相关

    apache程序内并不设置NOFILE，但可以在apachectl脚本里设置

    httpd进行两段config
    各MPM的 *_pre_config使用retain数据，只有retained->module_loads开始进行fork
        main.c调用了两边ap_run_pre_config只在第二次开始fork

    apr_pool_userdata_set、apr_pool_userdata_get

    ap_hook_open_logs阶段传入的Server_rec为最外层，即process级别的，并非每个virtualhost创建一个

    .htaccess里可以添加httpd配置,在不修改httpd.conf的情况下更改应用配置，比如RewriteRule
        这样会影响效率

jenkins
    使用windows部署jenkins，需要能通过PATH找到git，并能让git使用.ssh无密码访问代码库
        git会在HOME目录下寻找.ssh，如果没有设置回事系统默认值（这个默认值在windows上未知）

    jenkins中配置发送html邮件，主要有些子配置如果更改了默认邮件类型，需要单独配
        <a href="${BUILD_URL}">${BUILD_URL}</a>
        ${FILE,path="tests/daemon_cov.html"}
        ${BUILD_LOG}

Taint checking/trademarking
DMI Desktop Management Interface; SMBIOS, System Management BIOS

ssh-keygen -lf显示fingerprint

abrt会收集bug crash，生成core文件，但仅收集yum安装的包，设置/etc/abrt/*.conf中的
    ProcessUnpackaged = no可以允许其他程序生成core（因为abrt会接管系统的core生成）
    abrt运行时，sysctl -a|grep core_pattern，以'|'开头

grep -F不使用regexp，和xargs一起使用需要用-e否则不会执行
awk print可打印该行

head/tail -n参数可以使用+/-设置从第K开始

ps axfo pid,comm树形结构显示，BSD风格的命令行
    ps --forest -eo pid,comm POSIX风格

docker:
    docker run --rm -v /var/run/docker.sock:/var/run/docker.sock nate/dockviz images -t
    docker inspect --format '{{ .State.Pid }}' [container id/name]/[image]
    docker ps -a |tail -n +2 | awk '{print $1}'| xargs -I{} docker rm {}
    Ctrl+p+q从attach的container中退出
    docker attach container还不知道其语义
    docker export adoring_kowalevski > contents.tar对于不带sh/bash的可以这样查看文件
        但一般都会带sh，或者sh的符号链接
    docker ps -a仍然会显示exited的container，需要手动删除（为啥不直接删掉），加上–rm可以自动删除
    docker pull未下载完的image无法删掉，重启docker
    docker镜像为一系列readonly层，container启动后会在其上创建一个rw层
        docker将这种ro层之上存在rw层的组合为Union File System
        为了在container间共享数据，docker使用volumn的概念表示UFS之外存在于host的目录或文件
        如果不指定--name，volumn在inspect是看不到的，但是可以在container看到volumn
        -v src:dest可以指定某个host目录
        使用docker rm删除exit的container不会自动删除volumn，需要加-v或者启动时使用--rm
        处于exit状态的container可以看logs
    docker run需要foreground进程保持运行，否则整个container都会结束，可以使用supervisor
        或者使用bash循环保持在foreground
        -e指定环境变量
    docker exec执行bash，就算以root登陆，仍然没有root权限，需要添加--privileged
    docker container中监听的端口如果不polish在host上看不到，在/proc中也看不到

    CMD会被覆盖，ENTRYPOINT不会

    docker network
        bridge 即docker0，不支持自动服务发现
        none：无网络连接
        host：跟host一样
        docker run通过--net指定network，默认为bridge，每个container一个IP
        network分为：
            bridge network:当前host可用，可通过expose与其他host通信
            overlay network：支持跨host
    docker expose/publish, expose仅是标明我会监听，publish把这个端口绑定到host端

    docker build过程中失败，可以将中间过程tag，然后从中间过程开始，需要修改FROM

    busybox
        busybox的find、sed功能都很弱
    docker执行httpd报bad user name，但是这个user在passwd和group里面都有，为什么？？
        将/etc/nsswitch.conf中passwd和group配置为files，该配置依赖libnss_files.so.2
        这样就可以正确读取，配置为compat不行
    docker container运行时，dev/proc/sys会自动创建，不需要包含在image中，如果使用chroot
        测试image的依赖，可以临时创建
    ADD可以将压缩文件作为image的目录结构
    ENV可以设置container的环境变量，如PATH
    WORKDIR设置container工作目录

    docker cp <containerId>:/file/path/within/container /host/path/target

    docker run --add-host可以运行时添加hosts条目

cat > a.txt << EOF, 这样可以将cat的输出放到文件，重定向输出放到结果不管用

~/.bashrc ~/.bash_profile /etc/bashrc /etc/profile之间的关系
    chroot时/etc/bashrc没被读取，但是~/.bashrc被读取了

chroot时提示找不到/bin/bash，实际为该程序的ld.so不存在
chroot环境下不会自动创建dev设备，如果某程序需要，可自行创建，或者使用mount bind宿主机的dev
    mknod -m 0666 dev/null c 1 3
    mknod -m 0666 dev/random c 1 8
    mknod -m 0444 dev/urandom c 1 9

    mount -bind /dev /mnt/newroot/dev


vmstat -Sn --stats查看memory,swap,io, etc..

bash里\[\]用来表示non-printable字符的开始结束，否则针对过长的命令，会导致bash不能正确显示输入
    对应到ascii代码为\001和\002，在不能使用\[\]的情况可以使用这两个，如gdb prompt
bash里面$!表示上条后台命令的pid

bash里不容易写if，但是可以使用：run_aaa || exit来作为替代
bash用for循环解析空格分割的字符串：
    有效：var="aa abb"; for i in $var; do echo "$i"; done
        使用Makefile的变量也不行，需要复制过来
        Makefile里用$$来引用bash变量
    无效：for i in "aa abb"; do echo "$i"; done
    无效：var="aa abb"; for i in "$var"; do echo "$i"; done

    对文件内每一行
    cat peptides.txt | while read line
    do
       # do something with $line here
    done

    迭代数组for fname in a.txt b.txt c.txt
    for file in *.jtl; do
        wc -l $file |cut -d' ' -f 1 | awk '{print "'${file}'  "  $0/600.0}';
    done

    bash里的strstr：if [[ ${image_name} == *"apache"* ]];

diff --brief -r dir1/ dir2/

gdb处理宏，make KCFLAGS=-ggdb3
    macro expand task_is_stopped_or_traced(init_task)
    info macro task_is_stopped_or_traced
GNU版本的cp带--parents选项，可以自动创建目录

pthread_cleanup_push/pop
pthread_cond_wait调用完仍然是可以cancel的，应该是用信号实现的
    cancel时不消耗cond的signal计数

condition move固定损耗，而branch predicting在大概率失败时会对性能造成很大影响

disassemble 查看汇编 /m /r

查看是否chroot：/proc/<pid>/root，值为/表示没有chroot

chroot为/a/b/c后的进程A，如果连接/etc/file.sock 进程B监听/a/b/c/etc/file.sock
    这样是可以正常连接的

Provisioner - is something doing provision - in docker installing, running, pulling containers.

Provider - is something that runs the VM. I.e. VBox runs the ubuntu OS image.

docker and vagrant, They are very much complimentary.

gg=G vi中格式化代码

gettimeofday/time获取的时间既是UTC时间，不分时区，需要使用其他接口转成本地时间
C里面opaque pointer: typedef struct pmpi_s *pmpi;

readelf -s --wide

stub为依赖的函数提供伪实现，都不一定被调用。mock可以提供伪结果，且验证结果，验证调用
    这样看来daemon写的都是stub，而不是mock

unix-socket如果文件存在，bind会提示INUSE，另外该文件在试用期间不能随意删除，否则其他进程连不上
    使用文件权限设置连接权限，根据需要需要设定umask或者设定文件mode

获得IP地址 getent hosts <hostname>
badboy
    Assertion这个功能挺有意思
    Request Mode and Navigation Mode（Ctrl+Alt）
    Loop功能

Memory ordering describes the order of accesses to computer memory by a CPU. The term can refer either to the memory ordering generated by the compiler during compile time, or to the memory ordering generated by a CPU during runtime.

Memory model allow programmers to reason about the correctness of their programs, it also help programmer get most out the performance optimizations modern multi-core systems  can make.
A memory model is a specification that shows the allowed behavior of multi-threaded programs running on shared memory , multi core processors so programmer know what to expect when writing programs on these systems, the behavior is defined simply  in terms of memory reads and writes of memory locations  without any references to caches or memory subsystems.



在x86上下面的程序会产生r0 = r1 = 0的情况，从结构上是由于Store-buffer，也可以逻辑上从CPU memory
    ordering来理解
    或者这么说，这是由于Store-buffer，使得第二次的读取等同于在写入前面（memory ordering)
CORE-0                                CORE-1
x = 1                                 y = 1
asm volatile ("" ::: "memory");       asm volatile ("" ::: "memory");
r0 = y                                r1 = x


A strong hardware memory model is one in which every machine instruction comes implicitly with acquire and release semantics. As a result, when one CPU core performs a sequence of writes, every other CPU core sees those values change in the same order that they were written.
在ARM下，B核看到的store顺序与A核执行顺序未必一致
TSO stands for “total store order”

Memory barrier type：
    LoadLoad StoreStore
    LoadStore StoreLoad


'next' was not declared in this scope, and no declarations were found by argument-dependent lookup at the point of instantiation [-fpermissive],可以添加-fpermissive或者添加this->

-E -P可以去掉行号

execution plan also known as the EXPLAIN plan： explain select * from users;可以得到一系列op

linux-windows迁移，可通过FD_SETSIZE设置select支持的socket数目，这需要在引入
    winsock2.h的头文件前添加，可通过工程或makefile设置-DFD_SETSIZE=xxxx
    https://msdn.microsoft.com/zh-cn/library/windows/desktop/ms739169(v=vs.85).aspx

windows上如果一个extern符号设置错了,比如使用阶段，但设置了__declspec(export)
    这就会导致linker找不到符号，因为linker会尝试在本地代码中寻找符号
    相比起来linux并不把符号绑定到某个库上，.so在链接阶段并不会去解析外部符号
    而是推迟到load阶段，但windows上强制在链接阶段必须指定lib(对应的DLL)


-DskipTests这个只是skip执行，还是会编译
mvn clean install -Dmaven.test.skip=true

有些机器的ssh可能默认不开启publickey认证，这时配置私钥是不起作用的

unzip -d <dst-dir> -o : 自动覆盖，没有force，需要使用-o

思考的列表：
    一条方案未必是死胡同，可以继续按动态和静态两条线继续思考

yum install lrzsz
yum --nogpgcheck

pthread_mutex_lock/unlock隐含memory barriar操作

dwarf调试符号格式，linux目前的默认格式为dwarf2或者dwarf4的格式

Linux tracers
    以下trace都可以在程序运行中获取数据

    strace系统调用，可以抓正在运行的程序
        使用ptrace接口，需要暂停被trace的进程
    ltrace，可以trace库函数
    ftrace是一个kernel subsystem，类似dtrace
    perf_events
    eBPF
    SystemTap
    LTTng
    ktap
    sysdig

    gdb/strace/ltrace都使用ptrace API

    应用的kernel技术: kprobes/utrace/uprobes

pkg-config - Return metainformation about installed libraries
    默认在/usr/lib/pkgconfig, /usr/share/pkgconfig, /usr/local/lib/pkgconfig and /usr/local/share/pkgconfig搜索
    也可以用PKG_CONFIG_PATH配置

运行时寻找so可以使用
    LD_LIBRARY_PATH
    ldconfig配置ld.so.cache

.so中的符号是lazy处理，只在使用时才取resolve？？
有时有些so报undefined symbols，使用-Wl,--unresolved-symbols=xxx链接通过后的程序照样运行
    比如libgrpc.so.0包含对CRYPTO_free的外部引用，但是ldd中并不依赖ssl库，可能也是忽略掉了

update-alternatives - maintain symbolic links determining default commands,
    比如在多个JDK版本中切换，针对java/javac需要单独切换
    update-alternatives --config java

使用双引号，要转义$
ssh root@server "ps uax|grep bac | grep -v grep | awk '{ print \$2 }' > /tmp/back.tmp"

atyle --style=kr --mode=c -H 格式化代码

export LC_ALL=C让bash的glob大小写敏感

tar由很多格式: ustar/gnu/posix等

sort -nk5 noagent_cpu.log | tr -s ' ' | cut -d " " -f-5  | awk '{ printf "%x\n", $2,$5 }' | tail -n 20 | xargs -I{} grep 0x{} noagenttheaeddump.log

pid=23984; top -p $pid -b -n2 -d 1 | grep -w $pid | awk '{printf "%s,%s,%s,%s\n",$1,$12,$9,$10}'
pid=25891; top -p $pid -b -n1800 -d 1 > collector-cpu.log &

gnuplot画折线图

top -p $(ps -ef | grep [w]eblogic | awk '{print $2}')
kill -9 $(ps -ef | grep [w]eblogic | awk '{print $2}')
sort -k 3 -n 按第3列，按照数字方式排序


weblogic安装成功后，与/root/bes, /home/BES一起拷贝可以作为绿色安装


更新cpu microcode：microcode_ctl

weblogic非常慢，添加-Djava.security.egd=file:/dev/./urandom选项

ls &; sleep 1   这里&不需要添加';'
    ";" and "&" are command terminators, meaning fg and bg respectively


VNC centos7
    https://linux.cn/article-5335-1.html
    yum groupinstall "X Window System"
    yum install gnome-classic-session gnome-terminal nautilus-open-terminal control-center liberation-mono-fonts
    unlink /etc/systemd/system/default.target
    ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target
    reboot
    yum install tigervnc-server -y
    vncserver
    vncserver -kill :number (通过ps可看到)

Automatic Bug Reporting Tool, commonly abbreviated as ABRT
    进程崩溃后会写core文件，并在/var/log/messages里写入信息
    对于“Package 'jdk' isn't signed with proper key“，需要：
        Edit the file /etc/abrt/abrt-action-save-package-data.conf
        Set OpenGPGCheck = no
        Reload abrtd with the command: service abrtd reload

info symbol